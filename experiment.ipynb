{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multimodal Search"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Import + Embeddings computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/Users/baptiste/.cache/huggingface/datasets/detection-datasets___parquet/detection-datasets--coco-64ef6d5414f6b8df/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "100%|██████████| 2/2 [00:00<00:00, 10.84it/s]\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/multimodal-search/lib/python3.9/site-packages/transformers/models/convnext/feature_extraction_convnext.py:28: FutureWarning: The class ConvNextFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use ConvNextImageProcessor instead.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at microsoft/cvt-21-384 were not used when initializing CvtModel: ['layernorm.bias', 'classifier.bias', 'layernorm.weight', 'classifier.weight']\n",
      "- This IS expected if you are initializing CvtModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CvtModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.229, 0.224, 0.225]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://huggingface.co/datasets/detection-datasets/coco\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoFeatureExtractor, CvtForImageClassification\n",
    "\n",
    "\n",
    "dataset = load_dataset(\"detection-datasets/coco\")\n",
    "# dataset = load_dataset(\"beans\")\n",
    "\n",
    "# https://huggingface.co/blog/image-similarity\n",
    "\n",
    "from transformers import AutoFeatureExtractor, AutoModel\n",
    "\n",
    "# model_ckpt = \"nateraw/vit-base-beans\"\n",
    "# extractor = AutoFeatureExtractor.from_pretrained(model_ckpt)\n",
    "# model = AutoModel.from_pretrained(model_ckpt)\n",
    "\n",
    "extractor = AutoFeatureExtractor.from_pretrained('microsoft/cvt-21-384')\n",
    "model = AutoModel.from_pretrained('microsoft/cvt-21-384')\n",
    "device = \"mps\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 384, 384])\n",
      "torch.Size([1, 24, 24])\n"
     ]
    }
   ],
   "source": [
    "image = dataset[\"train\"][0][\"image\"]\n",
    "image = extractor(images=image, return_tensors=\"pt\")[\"pixel_values\"].to(device)\n",
    "print(image.shape)\n",
    "\n",
    "embeddings = model(image)\n",
    "print(embeddings.last_hidden_state[:, 0].shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|          | 0/117266 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 3, 384, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                 \r"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "output with shape [1, 384, 384] doesn't match the broadcast shape [3, 384, 384]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 49\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[39m# if coco embedding dataset is not on disk, do map\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(save_path):\n\u001b[0;32m---> 49\u001b[0m     dataset_emb \u001b[39m=\u001b[39m dataset\u001b[39m.\u001b[39;49mmap(extract_fn, batched\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, batch_size\u001b[39m=\u001b[39;49mbatch_size)\n\u001b[1;32m     50\u001b[0m     dataset_emb\u001b[39m.\u001b[39msave_to_disk(save_path)\n\u001b[1;32m     51\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/multimodal-search/lib/python3.9/site-packages/datasets/dataset_dict.py:852\u001b[0m, in \u001b[0;36mDatasetDict.map\u001b[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_names, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, desc)\u001b[0m\n\u001b[1;32m    849\u001b[0m \u001b[39mif\u001b[39;00m cache_file_names \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    850\u001b[0m     cache_file_names \u001b[39m=\u001b[39m {k: \u001b[39mNone\u001b[39;00m \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m}\n\u001b[1;32m    851\u001b[0m \u001b[39mreturn\u001b[39;00m DatasetDict(\n\u001b[0;32m--> 852\u001b[0m     {\n\u001b[1;32m    853\u001b[0m         k: dataset\u001b[39m.\u001b[39mmap(\n\u001b[1;32m    854\u001b[0m             function\u001b[39m=\u001b[39mfunction,\n\u001b[1;32m    855\u001b[0m             with_indices\u001b[39m=\u001b[39mwith_indices,\n\u001b[1;32m    856\u001b[0m             with_rank\u001b[39m=\u001b[39mwith_rank,\n\u001b[1;32m    857\u001b[0m             input_columns\u001b[39m=\u001b[39minput_columns,\n\u001b[1;32m    858\u001b[0m             batched\u001b[39m=\u001b[39mbatched,\n\u001b[1;32m    859\u001b[0m             batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[1;32m    860\u001b[0m             drop_last_batch\u001b[39m=\u001b[39mdrop_last_batch,\n\u001b[1;32m    861\u001b[0m             remove_columns\u001b[39m=\u001b[39mremove_columns,\n\u001b[1;32m    862\u001b[0m             keep_in_memory\u001b[39m=\u001b[39mkeep_in_memory,\n\u001b[1;32m    863\u001b[0m             load_from_cache_file\u001b[39m=\u001b[39mload_from_cache_file,\n\u001b[1;32m    864\u001b[0m             cache_file_name\u001b[39m=\u001b[39mcache_file_names[k],\n\u001b[1;32m    865\u001b[0m             writer_batch_size\u001b[39m=\u001b[39mwriter_batch_size,\n\u001b[1;32m    866\u001b[0m             features\u001b[39m=\u001b[39mfeatures,\n\u001b[1;32m    867\u001b[0m             disable_nullable\u001b[39m=\u001b[39mdisable_nullable,\n\u001b[1;32m    868\u001b[0m             fn_kwargs\u001b[39m=\u001b[39mfn_kwargs,\n\u001b[1;32m    869\u001b[0m             num_proc\u001b[39m=\u001b[39mnum_proc,\n\u001b[1;32m    870\u001b[0m             desc\u001b[39m=\u001b[39mdesc,\n\u001b[1;32m    871\u001b[0m         )\n\u001b[1;32m    872\u001b[0m         \u001b[39mfor\u001b[39;00m k, dataset \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems()\n\u001b[1;32m    873\u001b[0m     }\n\u001b[1;32m    874\u001b[0m )\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/multimodal-search/lib/python3.9/site-packages/datasets/dataset_dict.py:853\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    849\u001b[0m \u001b[39mif\u001b[39;00m cache_file_names \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    850\u001b[0m     cache_file_names \u001b[39m=\u001b[39m {k: \u001b[39mNone\u001b[39;00m \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m}\n\u001b[1;32m    851\u001b[0m \u001b[39mreturn\u001b[39;00m DatasetDict(\n\u001b[1;32m    852\u001b[0m     {\n\u001b[0;32m--> 853\u001b[0m         k: dataset\u001b[39m.\u001b[39;49mmap(\n\u001b[1;32m    854\u001b[0m             function\u001b[39m=\u001b[39;49mfunction,\n\u001b[1;32m    855\u001b[0m             with_indices\u001b[39m=\u001b[39;49mwith_indices,\n\u001b[1;32m    856\u001b[0m             with_rank\u001b[39m=\u001b[39;49mwith_rank,\n\u001b[1;32m    857\u001b[0m             input_columns\u001b[39m=\u001b[39;49minput_columns,\n\u001b[1;32m    858\u001b[0m             batched\u001b[39m=\u001b[39;49mbatched,\n\u001b[1;32m    859\u001b[0m             batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[1;32m    860\u001b[0m             drop_last_batch\u001b[39m=\u001b[39;49mdrop_last_batch,\n\u001b[1;32m    861\u001b[0m             remove_columns\u001b[39m=\u001b[39;49mremove_columns,\n\u001b[1;32m    862\u001b[0m             keep_in_memory\u001b[39m=\u001b[39;49mkeep_in_memory,\n\u001b[1;32m    863\u001b[0m             load_from_cache_file\u001b[39m=\u001b[39;49mload_from_cache_file,\n\u001b[1;32m    864\u001b[0m             cache_file_name\u001b[39m=\u001b[39;49mcache_file_names[k],\n\u001b[1;32m    865\u001b[0m             writer_batch_size\u001b[39m=\u001b[39;49mwriter_batch_size,\n\u001b[1;32m    866\u001b[0m             features\u001b[39m=\u001b[39;49mfeatures,\n\u001b[1;32m    867\u001b[0m             disable_nullable\u001b[39m=\u001b[39;49mdisable_nullable,\n\u001b[1;32m    868\u001b[0m             fn_kwargs\u001b[39m=\u001b[39;49mfn_kwargs,\n\u001b[1;32m    869\u001b[0m             num_proc\u001b[39m=\u001b[39;49mnum_proc,\n\u001b[1;32m    870\u001b[0m             desc\u001b[39m=\u001b[39;49mdesc,\n\u001b[1;32m    871\u001b[0m         )\n\u001b[1;32m    872\u001b[0m         \u001b[39mfor\u001b[39;00m k, dataset \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems()\n\u001b[1;32m    873\u001b[0m     }\n\u001b[1;32m    874\u001b[0m )\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/multimodal-search/lib/python3.9/site-packages/datasets/arrow_dataset.py:563\u001b[0m, in \u001b[0;36mtransmit_tasks.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    561\u001b[0m     \u001b[39mself\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mself\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    562\u001b[0m \u001b[39m# apply actual function\u001b[39;00m\n\u001b[0;32m--> 563\u001b[0m out: Union[\u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mDatasetDict\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    564\u001b[0m datasets: List[\u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(out\u001b[39m.\u001b[39mvalues()) \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(out, \u001b[39mdict\u001b[39m) \u001b[39melse\u001b[39;00m [out]\n\u001b[1;32m    565\u001b[0m \u001b[39mfor\u001b[39;00m dataset \u001b[39min\u001b[39;00m datasets:\n\u001b[1;32m    566\u001b[0m     \u001b[39m# Remove task templates if a column mapping of the template is no longer valid\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/multimodal-search/lib/python3.9/site-packages/datasets/arrow_dataset.py:528\u001b[0m, in \u001b[0;36mtransmit_format.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    521\u001b[0m self_format \u001b[39m=\u001b[39m {\n\u001b[1;32m    522\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtype\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_type,\n\u001b[1;32m    523\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mformat_kwargs\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_kwargs,\n\u001b[1;32m    524\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mcolumns\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_columns,\n\u001b[1;32m    525\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39moutput_all_columns\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output_all_columns,\n\u001b[1;32m    526\u001b[0m }\n\u001b[1;32m    527\u001b[0m \u001b[39m# apply actual function\u001b[39;00m\n\u001b[0;32m--> 528\u001b[0m out: Union[\u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mDatasetDict\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    529\u001b[0m datasets: List[\u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(out\u001b[39m.\u001b[39mvalues()) \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(out, \u001b[39mdict\u001b[39m) \u001b[39melse\u001b[39;00m [out]\n\u001b[1;32m    530\u001b[0m \u001b[39m# re-apply format to the output\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/multimodal-search/lib/python3.9/site-packages/datasets/arrow_dataset.py:2953\u001b[0m, in \u001b[0;36mDataset.map\u001b[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001b[0m\n\u001b[1;32m   2945\u001b[0m \u001b[39mif\u001b[39;00m transformed_dataset \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   2946\u001b[0m     \u001b[39mwith\u001b[39;00m logging\u001b[39m.\u001b[39mtqdm(\n\u001b[1;32m   2947\u001b[0m         disable\u001b[39m=\u001b[39m\u001b[39mnot\u001b[39;00m logging\u001b[39m.\u001b[39mis_progress_bar_enabled(),\n\u001b[1;32m   2948\u001b[0m         unit\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m examples\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2951\u001b[0m         desc\u001b[39m=\u001b[39mdesc \u001b[39mor\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mMap\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   2952\u001b[0m     ) \u001b[39mas\u001b[39;00m pbar:\n\u001b[0;32m-> 2953\u001b[0m         \u001b[39mfor\u001b[39;00m rank, done, content \u001b[39min\u001b[39;00m Dataset\u001b[39m.\u001b[39m_map_single(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mdataset_kwargs):\n\u001b[1;32m   2954\u001b[0m             \u001b[39mif\u001b[39;00m done:\n\u001b[1;32m   2955\u001b[0m                 shards_done \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/multimodal-search/lib/python3.9/site-packages/datasets/arrow_dataset.py:3329\u001b[0m, in \u001b[0;36mDataset._map_single\u001b[0;34m(shard, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset)\u001b[0m\n\u001b[1;32m   3325\u001b[0m indices \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\n\u001b[1;32m   3326\u001b[0m     \u001b[39mrange\u001b[39m(\u001b[39m*\u001b[39m(\u001b[39mslice\u001b[39m(i, i \u001b[39m+\u001b[39m batch_size)\u001b[39m.\u001b[39mindices(shard\u001b[39m.\u001b[39mnum_rows)))\n\u001b[1;32m   3327\u001b[0m )  \u001b[39m# Something simpler?\u001b[39;00m\n\u001b[1;32m   3328\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3329\u001b[0m     batch \u001b[39m=\u001b[39m apply_function_on_filtered_inputs(\n\u001b[1;32m   3330\u001b[0m         batch,\n\u001b[1;32m   3331\u001b[0m         indices,\n\u001b[1;32m   3332\u001b[0m         check_same_num_examples\u001b[39m=\u001b[39;49m\u001b[39mlen\u001b[39;49m(shard\u001b[39m.\u001b[39;49mlist_indexes()) \u001b[39m>\u001b[39;49m \u001b[39m0\u001b[39;49m,\n\u001b[1;32m   3333\u001b[0m         offset\u001b[39m=\u001b[39;49moffset,\n\u001b[1;32m   3334\u001b[0m     )\n\u001b[1;32m   3335\u001b[0m \u001b[39mexcept\u001b[39;00m NumExamplesMismatchError:\n\u001b[1;32m   3336\u001b[0m     \u001b[39mraise\u001b[39;00m DatasetTransformationNotAllowedError(\n\u001b[1;32m   3337\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mUsing `.map` in batched mode on a dataset with attached indexes is allowed only if it doesn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt create or remove existing examples. You can first run `.drop_index() to remove your index and then re-add it.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   3338\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/multimodal-search/lib/python3.9/site-packages/datasets/arrow_dataset.py:3210\u001b[0m, in \u001b[0;36mDataset._map_single.<locals>.apply_function_on_filtered_inputs\u001b[0;34m(pa_inputs, indices, check_same_num_examples, offset)\u001b[0m\n\u001b[1;32m   3208\u001b[0m \u001b[39mif\u001b[39;00m with_rank:\n\u001b[1;32m   3209\u001b[0m     additional_args \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (rank,)\n\u001b[0;32m-> 3210\u001b[0m processed_inputs \u001b[39m=\u001b[39m function(\u001b[39m*\u001b[39;49mfn_args, \u001b[39m*\u001b[39;49madditional_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfn_kwargs)\n\u001b[1;32m   3211\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(processed_inputs, LazyDict):\n\u001b[1;32m   3212\u001b[0m     processed_inputs \u001b[39m=\u001b[39m {\n\u001b[1;32m   3213\u001b[0m         k: v \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m processed_inputs\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mitems() \u001b[39mif\u001b[39;00m k \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m processed_inputs\u001b[39m.\u001b[39mkeys_to_format\n\u001b[1;32m   3214\u001b[0m     }\n",
      "Cell \u001b[0;32mIn[20], line 21\u001b[0m, in \u001b[0;36mextract_embeddings.<locals>.pp\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpp\u001b[39m(batch):\n\u001b[1;32m     20\u001b[0m     images \u001b[39m=\u001b[39m batch[\u001b[39m\"\u001b[39m\u001b[39mimage\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m---> 21\u001b[0m     images \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mstack([transformation_chain(image) \u001b[39mfor\u001b[39;00m image \u001b[39min\u001b[39;00m images])\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     22\u001b[0m     \u001b[39mprint\u001b[39m(images\u001b[39m.\u001b[39mshape)\n\u001b[1;32m     23\u001b[0m     \u001b[39m# bap i think create a stack to apply the transformation chain\u001b[39;00m\n\u001b[1;32m     24\u001b[0m     \u001b[39m# image_batch_transformed = torch.stack(\u001b[39;00m\n\u001b[1;32m     25\u001b[0m     \u001b[39m#     [transformation_chain(image) for image in images]\u001b[39;00m\n\u001b[1;32m     26\u001b[0m     \u001b[39m# )\u001b[39;00m\n\u001b[1;32m     27\u001b[0m     \u001b[39m# new_batch = {\"pixel_values\": image_batch_transformed.to(device)}\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[20], line 21\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpp\u001b[39m(batch):\n\u001b[1;32m     20\u001b[0m     images \u001b[39m=\u001b[39m batch[\u001b[39m\"\u001b[39m\u001b[39mimage\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m---> 21\u001b[0m     images \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mstack([transformation_chain(image) \u001b[39mfor\u001b[39;00m image \u001b[39min\u001b[39;00m images])\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     22\u001b[0m     \u001b[39mprint\u001b[39m(images\u001b[39m.\u001b[39mshape)\n\u001b[1;32m     23\u001b[0m     \u001b[39m# bap i think create a stack to apply the transformation chain\u001b[39;00m\n\u001b[1;32m     24\u001b[0m     \u001b[39m# image_batch_transformed = torch.stack(\u001b[39;00m\n\u001b[1;32m     25\u001b[0m     \u001b[39m#     [transformation_chain(image) for image in images]\u001b[39;00m\n\u001b[1;32m     26\u001b[0m     \u001b[39m# )\u001b[39;00m\n\u001b[1;32m     27\u001b[0m     \u001b[39m# new_batch = {\"pixel_values\": image_batch_transformed.to(device)}\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/multimodal-search/lib/python3.9/site-packages/torchvision/transforms/transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, img):\n\u001b[1;32m     94\u001b[0m     \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransforms:\n\u001b[0;32m---> 95\u001b[0m         img \u001b[39m=\u001b[39m t(img)\n\u001b[1;32m     96\u001b[0m     \u001b[39mreturn\u001b[39;00m img\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/multimodal-search/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/multimodal-search/lib/python3.9/site-packages/torchvision/transforms/transforms.py:270\u001b[0m, in \u001b[0;36mNormalize.forward\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, tensor: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m    263\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[39m        tensor (Tensor): Tensor image to be normalized.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[39m        Tensor: Normalized Tensor image.\u001b[39;00m\n\u001b[1;32m    269\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 270\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mnormalize(tensor, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmean, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstd, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minplace)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/multimodal-search/lib/python3.9/site-packages/torchvision/transforms/functional.py:360\u001b[0m, in \u001b[0;36mnormalize\u001b[0;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(tensor, torch\u001b[39m.\u001b[39mTensor):\n\u001b[1;32m    358\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mimg should be Tensor Image. Got \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(tensor)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 360\u001b[0m \u001b[39mreturn\u001b[39;00m F_t\u001b[39m.\u001b[39;49mnormalize(tensor, mean\u001b[39m=\u001b[39;49mmean, std\u001b[39m=\u001b[39;49mstd, inplace\u001b[39m=\u001b[39;49minplace)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/multimodal-search/lib/python3.9/site-packages/torchvision/transforms/functional_tensor.py:940\u001b[0m, in \u001b[0;36mnormalize\u001b[0;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[1;32m    938\u001b[0m \u001b[39mif\u001b[39;00m std\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    939\u001b[0m     std \u001b[39m=\u001b[39m std\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[0;32m--> 940\u001b[0m \u001b[39mreturn\u001b[39;00m tensor\u001b[39m.\u001b[39;49msub_(mean)\u001b[39m.\u001b[39mdiv_(std)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: output with shape [1, 384, 384] doesn't match the broadcast shape [3, 384, 384]"
     ]
    }
   ],
   "source": [
    "import torchvision.transforms as T\n",
    "import os\n",
    "\n",
    "# Data transformation chain.\n",
    "transformation_chain = T.Compose(\n",
    "    [\n",
    "        # use https://huggingface.co/microsoft/cvt-21-384 \n",
    "        T.Resize(384),\n",
    "        T.CenterCrop(384),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean=extractor.image_mean, std=extractor.image_std),\n",
    "        T\n",
    "    ]\n",
    ")\n",
    "\n",
    "def extract_embeddings(model: torch.nn.Module):\n",
    "    \"\"\"Utility to compute embeddings.\"\"\"\n",
    "    device = model.device\n",
    "\n",
    "    def pp(batch):\n",
    "        images = batch[\"image\"]\n",
    "        images = torch.stack([transformation_chain(image) for image in images]).to(device)\n",
    "        print(images.shape)\n",
    "        # bap i think create a stack to apply the transformation chain\n",
    "        # image_batch_transformed = torch.stack(\n",
    "        #     [transformation_chain(image) for image in images]\n",
    "        # )\n",
    "        # new_batch = {\"pixel_values\": image_batch_transformed.to(device)}\n",
    "        with torch.no_grad():\n",
    "            embeddings = model(images).last_hidden_state[:, 0].cpu()\n",
    "\n",
    "            # embeddings = model(**new_batch)\n",
    "            # embeddings = embeddings.last_hidden_state.cpu()\n",
    "            # print(embeddings.keys())\n",
    "            # print(embeddings.last_hidden_state.shape)\n",
    "            # \n",
    "        return {\"embeddings\": embeddings}\n",
    "\n",
    "    return pp\n",
    "\n",
    "\n",
    "batch_size = 16\n",
    "extract_fn = extract_embeddings(model.to(device))\n",
    "\n",
    "save_path = \"./data/coco_embeddings\"\n",
    "\n",
    "# if coco embedding dataset is not on disk, do map\n",
    "if not os.path.exists(save_path):\n",
    "    dataset_emb = dataset.map(extract_fn, batched=True, batch_size=batch_size)\n",
    "    dataset_emb.save_to_disk(save_path)\n",
    "else:\n",
    "    dataset_emb = load_dataset(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1185.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/baptiste/.cache/huggingface/datasets/downloads/extracted/fb3c1511c735d9d1ddc5c6e6a082fa39ab9b92605bd82d8dbc292c1a0dffb1a5/train/bean_rust/bean_rust_train.214.jpg', '/Users/baptiste/.cache/huggingface/datasets/downloads/extracted/fb3c1511c735d9d1ddc5c6e6a082fa39ab9b92605bd82d8dbc292c1a0dffb1a5/train/bean_rust/bean_rust_train.216.jpg', '/Users/baptiste/.cache/huggingface/datasets/downloads/extracted/fb3c1511c735d9d1ddc5c6e6a082fa39ab9b92605bd82d8dbc292c1a0dffb1a5/train/bean_rust/bean_rust_train.47.jpg', '/Users/baptiste/.cache/huggingface/datasets/downloads/extracted/fb3c1511c735d9d1ddc5c6e6a082fa39ab9b92605bd82d8dbc292c1a0dffb1a5/train/bean_rust/bean_rust_train.334.jpg', '/Users/baptiste/.cache/huggingface/datasets/downloads/extracted/fb3c1511c735d9d1ddc5c6e6a082fa39ab9b92605bd82d8dbc292c1a0dffb1a5/train/bean_rust/bean_rust_train.79.jpg']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# https://huggingface.co/course/chapter5/6?fw=pt#using-faiss-for-efficient-similarity-search\n",
    "\n",
    "dataset_emb.add_faiss_index(column=\"embeddings\")\n",
    "question_embedding = dataset_emb.tensor(dataset_emb[\"embeddings\"][0]).cpu().detach().numpy()\n",
    "# print(torch.tensor(question_embedding))\n",
    "\n",
    "\n",
    "\n",
    "scores, samples = dataset_emb.get_nearest_examples(\n",
    "    \"embeddings\", question_embedding, k=5\n",
    ")\n",
    "\n",
    "print(samples[\"image_file_path\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pix2Pix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/multimodal-search/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Fetching 15 files: 100%|██████████| 15/15 [00:00<00:00, 219980.98it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdiffusers\u001b[39;00m \u001b[39mimport\u001b[39;00m StableDiffusionInstructPix2PixPipeline, EulerAncestralDiscreteScheduler\n\u001b[1;32m      8\u001b[0m model_id \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtimbrooks/instruct-pix2pix\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> 9\u001b[0m pipe \u001b[39m=\u001b[39m StableDiffusionInstructPix2PixPipeline\u001b[39m.\u001b[39;49mfrom_pretrained(model_id, torch_dtype\u001b[39m=\u001b[39;49mtorch\u001b[39m.\u001b[39;49mfloat16, safety_checker\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m     10\u001b[0m pipe\u001b[39m.\u001b[39mto(\u001b[39m\"\u001b[39m\u001b[39mmps\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     11\u001b[0m pipe\u001b[39m.\u001b[39mscheduler \u001b[39m=\u001b[39m EulerAncestralDiscreteScheduler\u001b[39m.\u001b[39mfrom_config(pipe\u001b[39m.\u001b[39mscheduler\u001b[39m.\u001b[39mconfig)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/multimodal-search/lib/python3.9/site-packages/diffusers/pipelines/pipeline_utils.py:944\u001b[0m, in \u001b[0;36mDiffusionPipeline.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    942\u001b[0m \u001b[39m# check if the module is in a subdirectory\u001b[39;00m\n\u001b[1;32m    943\u001b[0m \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39misdir(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(cached_folder, name)):\n\u001b[0;32m--> 944\u001b[0m     loaded_sub_model \u001b[39m=\u001b[39m load_method(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(cached_folder, name), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mloading_kwargs)\n\u001b[1;32m    945\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    946\u001b[0m     \u001b[39m# else load from the root directory\u001b[39;00m\n\u001b[1;32m    947\u001b[0m     loaded_sub_model \u001b[39m=\u001b[39m load_method(cached_folder, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mloading_kwargs)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/multimodal-search/lib/python3.9/site-packages/diffusers/models/modeling_utils.py:563\u001b[0m, in \u001b[0;36mModelMixin.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    561\u001b[0m \u001b[39mif\u001b[39;00m device_map \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    562\u001b[0m     param_device \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 563\u001b[0m     state_dict \u001b[39m=\u001b[39m load_state_dict(model_file, variant\u001b[39m=\u001b[39;49mvariant)\n\u001b[1;32m    564\u001b[0m     \u001b[39m# move the params from meta device to cpu\u001b[39;00m\n\u001b[1;32m    565\u001b[0m     missing_keys \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m(model\u001b[39m.\u001b[39mstate_dict()\u001b[39m.\u001b[39mkeys()) \u001b[39m-\u001b[39m \u001b[39mset\u001b[39m(state_dict\u001b[39m.\u001b[39mkeys())\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/multimodal-search/lib/python3.9/site-packages/diffusers/models/modeling_utils.py:101\u001b[0m, in \u001b[0;36mload_state_dict\u001b[0;34m(checkpoint_file, variant)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    100\u001b[0m     \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mbasename(checkpoint_file) \u001b[39m==\u001b[39m _add_variant(WEIGHTS_NAME, variant):\n\u001b[0;32m--> 101\u001b[0m         \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mload(checkpoint_file, map_location\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcpu\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m    102\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    103\u001b[0m         \u001b[39mreturn\u001b[39;00m safetensors\u001b[39m.\u001b[39mtorch\u001b[39m.\u001b[39mload_file(checkpoint_file, device\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/multimodal-search/lib/python3.9/site-packages/torch/serialization.py:789\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    787\u001b[0m             \u001b[39mexcept\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    788\u001b[0m                 \u001b[39mraise\u001b[39;00m pickle\u001b[39m.\u001b[39mUnpicklingError(UNSAFE_MESSAGE \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(e)) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m--> 789\u001b[0m         \u001b[39mreturn\u001b[39;00m _load(opened_zipfile, map_location, pickle_module, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mpickle_load_args)\n\u001b[1;32m    790\u001b[0m \u001b[39mif\u001b[39;00m weights_only:\n\u001b[1;32m    791\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/multimodal-search/lib/python3.9/site-packages/torch/serialization.py:1131\u001b[0m, in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1129\u001b[0m unpickler \u001b[39m=\u001b[39m UnpicklerWrapper(data_file, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpickle_load_args)\n\u001b[1;32m   1130\u001b[0m unpickler\u001b[39m.\u001b[39mpersistent_load \u001b[39m=\u001b[39m persistent_load\n\u001b[0;32m-> 1131\u001b[0m result \u001b[39m=\u001b[39m unpickler\u001b[39m.\u001b[39;49mload()\n\u001b[1;32m   1133\u001b[0m torch\u001b[39m.\u001b[39m_utils\u001b[39m.\u001b[39m_validate_loaded_sparse_tensors()\n\u001b[1;32m   1135\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/multimodal-search/lib/python3.9/site-packages/torch/_utils.py:153\u001b[0m, in \u001b[0;36m_rebuild_tensor_v2\u001b[0;34m(storage, storage_offset, size, stride, requires_grad, backward_hooks)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_rebuild_tensor_v2\u001b[39m(\n\u001b[1;32m    151\u001b[0m     storage, storage_offset, size, stride, requires_grad, backward_hooks\n\u001b[1;32m    152\u001b[0m ):\n\u001b[0;32m--> 153\u001b[0m     tensor \u001b[39m=\u001b[39m _rebuild_tensor(storage, storage_offset, size, stride)\n\u001b[1;32m    154\u001b[0m     tensor\u001b[39m.\u001b[39mrequires_grad \u001b[39m=\u001b[39m requires_grad\n\u001b[1;32m    155\u001b[0m     \u001b[39m# NB: This line exists only for backwards compatibility; the\u001b[39;00m\n\u001b[1;32m    156\u001b[0m     \u001b[39m# general expectation is that backward_hooks is an empty\u001b[39;00m\n\u001b[1;32m    157\u001b[0m     \u001b[39m# OrderedDict.  See Note [Don't serialize hooks]\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/multimodal-search/lib/python3.9/site-packages/torch/_utils.py:146\u001b[0m, in \u001b[0;36m_rebuild_tensor\u001b[0;34m(storage, storage_offset, size, stride)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_rebuild_tensor\u001b[39m(storage, storage_offset, size, stride):\n\u001b[1;32m    145\u001b[0m     \u001b[39m# first construct a tensor with the correct dtype/device\u001b[39;00m\n\u001b[0;32m--> 146\u001b[0m     t \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mtensor([], dtype\u001b[39m=\u001b[39;49mstorage\u001b[39m.\u001b[39;49mdtype, device\u001b[39m=\u001b[39;49mstorage\u001b[39m.\u001b[39;49muntyped()\u001b[39m.\u001b[39;49mdevice)\n\u001b[1;32m    147\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mset_(storage\u001b[39m.\u001b[39muntyped(), storage_offset, size, stride)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# https://huggingface.co/timbrooks/instruct-pix2pix\n",
    "\n",
    "import PIL\n",
    "import requests\n",
    "import torch\n",
    "from diffusers import StableDiffusionInstructPix2PixPipeline, EulerAncestralDiscreteScheduler\n",
    "\n",
    "model_id = \"timbrooks/instruct-pix2pix\"\n",
    "pipe = StableDiffusionInstructPix2PixPipeline.from_pretrained(model_id, torch_dtype=torch.float16, safety_checker=None)\n",
    "pipe.to(\"mps\")\n",
    "pipe.scheduler = EulerAncestralDiscreteScheduler.from_config(pipe.scheduler.config)\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/timothybrooks/instruct-pix2pix/main/imgs/example.jpg\"\n",
    "def download_image(url):\n",
    "    image = PIL.Image.open(requests.get(url, stream=True).raw)\n",
    "    image = PIL.ImageOps.exif_transpose(image)\n",
    "    image = image.convert(\"RGB\")\n",
    "    return image\n",
    "image = download_image(url)\n",
    "\n",
    "prompt = \"turn him into cyborg\"\n",
    "images = pipe(prompt, image=image, num_inference_steps=10, image_guidance_scale=1).images\n",
    "images[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/multimodal-search/lib/python3.9/site-packages/gradio/utils.py:951: UserWarning: Expected 1 arguments for function <function image_classifier at 0x2caaf4ee0>, received 2.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/multimodal-search/lib/python3.9/site-packages/gradio/utils.py:959: UserWarning: Expected maximum 1 arguments for function <function image_classifier at 0x2caaf4ee0>, received 2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7861\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def image_classifier(inp):\n",
    "    return {'cat': 0.3, 'dog': 0.7}\n",
    "\n",
    "# 3 images return the modified image, the most similiar to the input image, and the most similiar to the modified images\n",
    "# todo make this return n most similiar images\n",
    "demo = gr.Interface(fn=image_classifier, inputs=[\"image\", \"text\"], outputs=[\"image\", \"image\", \"image\"])\n",
    "demo.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multimodal-search",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
